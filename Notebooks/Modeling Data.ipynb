{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75edd90",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #5A96E3; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 45px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  4. Modeling Data </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641db125",
   "metadata": {},
   "source": [
    "### 4.1 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95a1dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings  # Để loại bỏ các warning\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e986a6",
   "metadata": {},
   "source": [
    "## 4.2 Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbe850ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>700.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>35.99</td>\n",
       "      <td>17.35</td>\n",
       "      <td>32.90</td>\n",
       "      <td>20.33</td>\n",
       "      <td>26.64</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>847.82</td>\n",
       "      <td>2.46</td>\n",
       "      <td>38.04</td>\n",
       "      <td>18.06</td>\n",
       "      <td>36.24</td>\n",
       "      <td>23.32</td>\n",
       "      <td>30.54</td>\n",
       "      <td>9.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>894.55</td>\n",
       "      <td>5.25</td>\n",
       "      <td>38.39</td>\n",
       "      <td>23.25</td>\n",
       "      <td>41.01</td>\n",
       "      <td>24.16</td>\n",
       "      <td>31.93</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>827.79</td>\n",
       "      <td>6.20</td>\n",
       "      <td>36.33</td>\n",
       "      <td>33.98</td>\n",
       "      <td>43.39</td>\n",
       "      <td>23.20</td>\n",
       "      <td>30.91</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>660.90</td>\n",
       "      <td>3.69</td>\n",
       "      <td>29.13</td>\n",
       "      <td>54.36</td>\n",
       "      <td>35.76</td>\n",
       "      <td>19.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dt  aqi      co    no    no2     o3    so2  pm2_5   pm10  \\\n",
       "0  2021-01-01 00:00:00    3  700.95  0.44  35.99  17.35  32.90  20.33  26.64   \n",
       "1  2021-01-01 01:00:00    3  847.82  2.46  38.04  18.06  36.24  23.32  30.54   \n",
       "2  2021-01-01 02:00:00    3  894.55  5.25  38.39  23.25  41.01  24.16  31.93   \n",
       "3  2021-01-01 03:00:00    3  827.79  6.20  36.33  33.98  43.39  23.20  30.91   \n",
       "4  2021-01-01 04:00:00    2  660.90  3.69  29.13  54.36  35.76  19.50  25.60   \n",
       "\n",
       "    nh3  \n",
       "0  8.99  \n",
       "1  9.37  \n",
       "2  9.25  \n",
       "3  8.61  \n",
       "4  6.21  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('../Data/air_pollution_cleaned.csv')\n",
    "\n",
    "# Xem mẫu dữ liệu\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637b41e",
   "metadata": {},
   "source": [
    "## 4.3 The problem needs to be solve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd299e90",
   "metadata": {},
   "source": [
    "\n",
    "- Classify the aqi index based on the concentration levels of pollutants: no, co, so2, no2, o3, pm2_5, pm10, nh3.\n",
    "    - Input: no, co, so2, no2, o3, pm2_5, pm10, nh3.\n",
    "    - Output: aqi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cde180",
   "metadata": {},
   "source": [
    "## 4.4 Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cffd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  features (X) \n",
    "X = data[['no', 'co', 'so2', 'no2', 'pm2_5', 'pm10', 'nh3']]  \n",
    "#target variable (y)\n",
    "y = data['aqi']  # Chọn cột AQI làm target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd8abb",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "264d8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Standardisation)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e173dee0",
   "metadata": {},
   "source": [
    "### Divide the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0118cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee2b2324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.74524674,  4.07667137,  1.58271265, ...,  3.05853296,\n",
       "         3.40840197,  3.88376539],\n",
       "       [-0.6461352 , -0.4186191 , -0.11226167, ..., -0.56421195,\n",
       "        -0.55805232, -0.19491982],\n",
       "       [-0.59461859, -0.53831987, -0.12899183, ..., -0.29559602,\n",
       "        -0.29000729, -0.51291208],\n",
       "       ...,\n",
       "       [-0.60102613, -0.4186191 , -0.51134569, ..., -0.32624926,\n",
       "        -0.32848684, -0.51291208],\n",
       "       [-0.25091823, -0.47624813,  0.85146525, ..., -0.40454428,\n",
       "        -0.32291167,  0.43901972],\n",
       "       [ 0.29346624,  0.26409702,  1.44991701, ...,  0.28816965,\n",
       "         0.23569767,  0.06376841]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9218ca09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59103037, -0.56491636, -0.31197795, ..., -0.63352027,\n",
       "        -0.67720774, -0.4024839 ],\n",
       "       [-0.38265722, -0.32995751,  0.07037591, ..., -0.41808587,\n",
       "        -0.45759009, -0.15606547],\n",
       "       [ 0.36215505,  0.02470211,  0.88492557, ..., -0.19095646,\n",
       "        -0.1697587 , -0.06608695],\n",
       "       ...,\n",
       "       [-0.55155993, -0.09942809,  0.31958558, ..., -0.05800265,\n",
       "         0.02078065, -0.01394031],\n",
       "       [ 1.0036778 ,  0.38822723,  0.05364575, ...,  0.3993338 ,\n",
       "         0.50068183,  0.29689456],\n",
       "       [ 1.59957887,  0.88474804,  0.33631574, ...,  0.83192608,\n",
       "         0.77561382,  0.64658379]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1f3badf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17799    5\n",
       "19980    2\n",
       "8047     4\n",
       "6745     2\n",
       "29311    2\n",
       "        ..\n",
       "16850    5\n",
       "6265     3\n",
       "11284    4\n",
       "860      4\n",
       "15795    5\n",
       "Name: aqi, Length: 27050, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "773aab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14673    2\n",
       "12610    4\n",
       "10838    5\n",
       "9273     4\n",
       "1275     4\n",
       "        ..\n",
       "103      2\n",
       "20024    4\n",
       "11679    5\n",
       "16604    5\n",
       "15067    5\n",
       "Name: aqi, Length: 6763, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c8e8f",
   "metadata": {},
   "source": [
    "### 4.4.1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121419dc",
   "metadata": {},
   "source": [
    "- A Decision Tree is a supervised machine learning model used for classification tasks. It works by splitting data into subsets based on feature values, creating a hierarchical tree structure. Each internal node represents a feature or attribute, each branch corresponds to a decision rule, and each leaf node represents a class label. At each step, the model chooses the feature and splitting criterion that best separates the classes, commonly using metrics like Gini Impurity or Entropy (Information Gain) to evaluate the quality of splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afef8ec",
   "metadata": {},
   "source": [
    "- The tree continues to grow until a stopping condition is met, such as reaching a maximum depth, a minimum number of samples in a node, or achieving subsets that are pure (all samples belong to the same class). During prediction, the model traverses the tree from the root to a leaf based on the input feature values, assigning the corresponding class label at the leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f998c1f",
   "metadata": {},
   "source": [
    "We constructed a Decision Tree model with a relatively simple structure. The model used the entropy impurity criterion, with a maximum tree depth of 5, a minimum of 2 samples required to split a node, and at least 1 sample per leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54a59bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# train Decision Tree model\n",
    "decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7422e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ( using CV ): [0.78262477 0.79057301 0.78151571 0.78262477 0.78539741]\n"
     ]
    }
   ],
   "source": [
    "# Cross_validation (split train data into 5 foldsfolds )\n",
    "cross_validation_scores = cross_val_score(decision_tree_model, X_train, y_train, cv=5)\n",
    "print(\"Accuracy ( using CV ):\", cross_validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a5b6ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (on test set): 0.7826408398639657\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "test_accuracy = decision_tree_model.score(X_test, y_test)\n",
    "print(f'Accuracy (on test set): {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce0ac1",
   "metadata": {},
   "source": [
    "\n",
    "- As we can see, using cross-validation and evaluation on the test gives us quite similar results (77%). This indicates that our model is quite good\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef6d8a",
   "metadata": {},
   "source": [
    "\n",
    "### Classification report:\n",
    "- Precision: is the proportion of the class that assigns a label to positive is actually positive.\n",
    "- Recall: is the positive sample rate assigned by the classifier.\n",
    "- F11-score: A combination of precision and recall. F1-score = 2*(precision * recall)/(precision + recall).\n",
    "- Support: The number of actual data points in each class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45488077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.94      0.91       193\n",
      "           2       0.84      0.94      0.89      1545\n",
      "           3       0.56      0.36      0.44      1151\n",
      "           4       0.60      0.65      0.63      1446\n",
      "           5       0.91      0.95      0.93      2428\n",
      "\n",
      "    accuracy                           0.78      6763\n",
      "   macro avg       0.76      0.77      0.76      6763\n",
      "weighted avg       0.77      0.78      0.77      6763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test \n",
    "y_pred_tree = decision_tree_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73015ced",
   "metadata": {},
   "source": [
    "- Classes 1 and 5:\n",
    "    - High performance with Precision, Recall, and F1-Score reach over 90%. This indicates that the model is very effective at classifying these two classes, with minimal misclassification.\n",
    "- Class 2:\n",
    "    - Precision and Recall are around 89-91%, showing that the model handles this class quite well.\n",
    "- Classes 3 and 4:\n",
    "    - The performance is significantly lower for these classes (F1-Score ~52% for Class 3 and ~58% for Class 4). This may be due to imbalanced data distribution or insufficient distinct features for these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5afdae",
   "metadata": {},
   "source": [
    "**GridSearchCV**\n",
    "- We will use GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Accuracy: 0.7947504621072089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Init Decision Tree\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "# Define the grid of hyperparameters to search \n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [ 5, 10, 15, 20,25],\n",
    "    'min_samples_split': [1, 2, 5, 15, 25],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "#  Perform grid search with cross-validation\n",
    "gridcv_decision_tree = GridSearchCV(DT_model, param_grid, cv=5, scoring='accuracy')\n",
    "gridcv_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", gridcv_decision_tree.best_params_)\n",
    "print(\"Best Accuracy:\", gridcv_decision_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602ecf0",
   "metadata": {},
   "source": [
    "Now we have the hyperparameters and we gonna apply into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "929a5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7929912760609197\n"
     ]
    }
   ],
   "source": [
    "# valuate the model on the test set using the best hyperparameters\n",
    "best_model_tree = gridcv_decision_tree.best_estimator_\n",
    "y_pred = best_model_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61913b",
   "metadata": {},
   "source": [
    "### Now we will apply this model with sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample\n",
    "sample = {\n",
    "    'no': 0.09,\n",
    "    'co': 500.76,\n",
    "    'so2': 26,\n",
    "    'no2': 14.43,\n",
    "    'pm2_5': 22.5,\n",
    "    'pm10': 35.2,\n",
    "    'nh3': 12,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c10f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AQI: [2]\n"
     ]
    }
   ],
   "source": [
    "#Predict aqi\n",
    "predict_df = pd.DataFrame([sample])\n",
    "new_sample = scaler.transform(predict_df) \n",
    "predicted_aqi = best_model_tree.predict(new_sample)\n",
    "\n",
    "print(f'AQI: {predicted_aqi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baf1dc",
   "metadata": {},
   "source": [
    "### 4.4.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487241c",
   "metadata": {},
   "source": [
    "- Random Forest is a machine learning algorithm based on the ensemble method, utilizing multiple decision trees to solve classification and regression problems. It is one of the most powerful and popular models due to its ability to minimize overfitting and improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef317b15",
   "metadata": {},
   "source": [
    "- How It Works: \n",
    "    - The initial dataset is divided into multiple subsets using the bootstrap sampling method (random sampling with replacement).\n",
    "    - Each decision tree is built on a different subset, using a random subset of features selected at each split.\n",
    "    - This use of different data subsets and features ensures the trees are independent and reduces correlation among them.\n",
    "    - Classification: For each data point, the trees in the forest make individual predictions. The final output is determined based on the majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a09b1f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.80924214 0.82107209 0.81774492 0.81441774 0.8168207 ]\n",
      "Test Accuracy: 0.8181280496820937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Init \n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "# train Decision Tree model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation on train set\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "#  Predict on the test set\n",
    "test_accuracy = rf_model.score(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081529a",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91ea73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.92      0.93       193\n",
      "           2       0.89      0.94      0.92      1545\n",
      "           3       0.65      0.53      0.59      1151\n",
      "           4       0.66      0.68      0.67      1446\n",
      "           5       0.91      0.95      0.93      2428\n",
      "\n",
      "    accuracy                           0.82      6763\n",
      "   macro avg       0.81      0.80      0.81      6763\n",
      "weighted avg       0.81      0.82      0.81      6763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test \n",
    "y_pred_RF = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b2dd6",
   "metadata": {},
   "source": [
    "- Class 1: High precision (0.95) and recall (0.92) demonstrate that the model performs well in identifying this class, with few false positives.\n",
    "- Class 2: Outstanding performance with the highest recall (0.94) and an F1-score of 0.92, indicating the model correctly identifies most data points in this class.\n",
    "- Class 3: The weakest performance, with an F1-score of 0.59. Both precision (0.65) and recall (0.53) are low, suggesting the model struggles to classify this class accurately. This could be due to overlapping features with other classes or insufficient class-specific data.\n",
    "- Class 4: Moderate performance with an F1-score of 0.67. Recall (0.68) is slightly higher than precision (0.66), indicating some false positives for this class.\n",
    "- Class 5: Excellent performance with an F1-score of 0.93 and recall of 0.95, showing that the model accurately identifies most instances of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17171ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 40}\n",
      "Best Accuracy: 0.8082809611829944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Init RandomForest model\n",
    "RF_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search \n",
    "param_grid = {\n",
    "    'n_estimators': [20, 40, 50],\n",
    "    'max_depth': [2,5,7,9],\n",
    "    'min_samples_split': [2,5,7],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'max_features': ['sqrt', 'log2'],    \n",
    "    'bootstrap': [True, False]   \n",
    "}\n",
    "\n",
    "#  Perform grid search with cross-validation\n",
    "gridcv_RF = GridSearchCV(RF_model, param_grid, cv=5, scoring='accuracy')\n",
    "gridcv_RF.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", gridcv_RF.best_params_)\n",
    "print(\"Best Accuracy:\", gridcv_RF.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "219a782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8002365813987875\n"
     ]
    }
   ],
   "source": [
    "best_model_RF = gridcv_RF.best_estimator_\n",
    "y_pred = gridcv_RF.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bad62011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new sample\n",
    "sample_RF = {\n",
    "    'no': 0.09,\n",
    "    'co': 300.76,\n",
    "    'so2': 16,\n",
    "    'no2': 14.43,\n",
    "    'pm2_5': 22.5,\n",
    "    'pm10': 35.2,\n",
    "    'nh3': 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a9b9a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AQI: [2]\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame([sample_RF])\n",
    "new_sample = scaler.transform(new_df)\n",
    "predicted_aqi = best_model_RF.predict(new_sample)\n",
    "#Predict aqi\n",
    "print(f' AQI: {predicted_aqi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97bd32-37ef-4013-b5ae-0212158703a6",
   "metadata": {},
   "source": [
    "### 4.4.3. SVM Model\n",
    "The Support Vector Machine (SVM) model is a supervised learning algorithm primarily used for classification and regression problems. SVM focuses on finding the best decision boundary to separate different data classes.\n",
    "\n",
    "How SVM Works:\n",
    "\n",
    "- Finding the Decision Boundary:\n",
    "\n",
    "   - For multi-dimensional data, SVM aims to identify a decision boundary (hyperplane) that separates data points into different classes. In binary classification problems, this boundary is a straight line. In higher-dimensional spaces, it becomes a hyperplane.\n",
    "- Optimizing the Boundary:\n",
    "\n",
    "   - SVM seeks to find the most optimal boundary by choosing one that maximizes the distance from the closest data points to the boundary. These closest data pointss are known as support vectors.\n",
    "- Kernel Trick:\n",
    "   - When the data cannot be separated linearly, SVM uses the kernel trick to map the data into a higher-dimensional feature space where it can be linearly separated.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa6148",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba8e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.75656192 0.76303142 0.75951941 0.76118299 0.76469501]\n",
      "Test Accuracy: 0.7530681650155256\n"
     ]
    }
   ],
   "source": [
    "#init SVM model\n",
    "svm_model = SVC(kernel='linear', C=5, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "# cross validation on train set \n",
    "cv_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "test_accuracy = svm_model.score(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b9ba3",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8e1343c-84af-4498-b31c-fee895351be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.76      0.79       193\n",
      "           2       0.84      0.89      0.86      1545\n",
      "           3       0.49      0.48      0.49      1151\n",
      "           4       0.57      0.56      0.56      1446\n",
      "           5       0.92      0.91      0.91      2428\n",
      "\n",
      "    accuracy                           0.75      6763\n",
      "   macro avg       0.73      0.72      0.72      6763\n",
      "weighted avg       0.75      0.75      0.75      6763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "# classification_report\n",
    "print(\"\\nclassification_report:\")\n",
    "print(classification_report(y_test,y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a062575",
   "metadata": {},
   "source": [
    "- Class 1: Precision (0.83) is reasonably high, but recall (0.76) is lower, indicating that while most predicted Class 1 instances are correct, some true instances of Class 1 are missed by the model.\n",
    "- Class 2: Good performance with both precision (0.84) and recall (0.89), resulting in an F1-score of 0.86. The model performs well in identifying most instances of this class.\n",
    "- Class 3: The lowest performance with precision (0.49) and recall (0.48), leading to a low F1-score of 0.49. The model struggles to accurately classify Class 3, likely due to data overlap or insufficient feature differentiation between classes.\n",
    "- Class 4: Moderate performance with precision (0.57) and recall (0.56), resulting in an F1-score of 0.56. The model faces challenges distinguishing this class from others, possibly due to ambiguous class boundaries.\n",
    "- Class 5: High performance with precision (0.92) and recall (0.91), leading to a strong F1-score of 0.91. The model effectively identifies most instances of this class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a43c2-37f2-4507-9d1e-8dd2802e23c9",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "be138278-a5a1-4667-9d1a-a0706caa2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 10\n",
      "Best Accuracy: 0.7619223659889094\n"
     ]
    }
   ],
   "source": [
    "# Tạo một mô hình SVM\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Định nghĩa các giá trị C để thử nghiệm\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Tạo một GridSearchCV\n",
    "svm_grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Huấn luyện GridSearchCV trên dữ liệu\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra giá trị C tốt nhất được chọn\n",
    "print(\"Best C:\", svm_grid_search.best_params_['C'])\n",
    "\n",
    "# In ra độ chính xác tốt nhất trên tập kiểm tra\n",
    "print(\"Best Accuracy:\", svm_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d55a4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create samplesample\n",
    "sample = {\n",
    "    'no': 0.09,\n",
    "    'co': 300.76,\n",
    "    'so2': 16,\n",
    "    'no2': 14.43,\n",
    "    'pm2_5': 22.5,\n",
    "    'pm10': 35.2,\n",
    "    'nh3': 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f82fb4-6b05-4d8d-bc7a-b71d820fedae",
   "metadata": {},
   "source": [
    "Now we will apply the newest model we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5ea7710d-7ae6-4255-85ef-a7504d7de940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AQI: [2]\n"
     ]
    }
   ],
   "source": [
    "best_svm_model = svm_grid_search.best_estimator_\n",
    "new_df = pd.DataFrame([sample ])\n",
    "new_sample = scaler.transform(new_df)\n",
    "\n",
    "# Predict aqi\n",
    "predicted_aqi =  best_svm_model.predict(new_sample)\n",
    "\n",
    "print(f'Predicted AQI: {predicted_aqi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48671e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615794e",
   "metadata": {},
   "source": [
    "### The comparison between models:\n",
    "\n",
    "1. Decision Tree:\n",
    "    - Advantages:\n",
    "\n",
    "        - Easy to understand and visualize. Decision rules are transparent.\n",
    "        - Can model non-linear relationships between features.\n",
    "        - Does not require normalization or standardization of data.\n",
    "    - Disadvantages:\n",
    "\n",
    "        - Overfitting: Prone to overfitting, especially with deep trees and small datasets.\n",
    "        - Instability: Small changes in the data can lead to large changes in the model structure.\n",
    "        - Tends to be biased toward classes with more data points, leading to poor performance on imbalanced datasets.\n",
    "4.  Random Forest (RF):\n",
    "    - Advantages:\n",
    "\n",
    "        - By combining multiple decision trees, Random Forest reduces overfitting compared to a single decision tree.\n",
    "        - Typically yields better performance and generalization than a single Decision Tree.\n",
    "        -  Scalable to large datasets.\n",
    "    - Disadvantages:\n",
    "        - Less interpretable than a single decision tree due to the ensemble nature.\n",
    "        - Requires more memory and processing power, especially with a large number of trees.\n",
    "        - Training multiple trees can be time-consuming.\n",
    "3. SVM (Support Vector Machine):\n",
    "    - Advantages:\n",
    "        - SVM is powerful when dealing with high-dimensional data.\n",
    "        - Performs well with small to medium-sized datasets, especially when the classes are well-separated.\n",
    "        - By maximizing the margin, SVM tends to avoid overfitting, especially with the use of regularization (C parameter).\n",
    "        - The ability to apply kernels allows SVM to work on non-linearly separable data.\n",
    "    - Disadvantages:\n",
    "\n",
    "        - Training time is high, especially for large datasets.\n",
    "        - The performance depends heavily on the choice of kernel, regularization, and other hyperparameters.\n",
    "        - SVM models are not easily interpretable, especially in high-dimensional spaces.\n",
    "        - SVM is sensitive to feature scaling and may perform poorly without proper normalization or standardization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
